{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting lxml>=3.1.0 (from python-docx)\n",
      "  Downloading lxml-5.3.0-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting typing-extensions>=4.9.0 (from python-docx)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Downloading lxml-5.3.0-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.8/3.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.8/3.8 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.6/3.8 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 3.9 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, lxml, python-docx\n",
      "Successfully installed lxml-5.3.0 python-docx-1.1.2 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting python-pptx\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting Pillow>=3.3.2 (from python-pptx)\n",
      "  Using cached pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
      "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from python-pptx) (5.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from python-pptx) (4.12.2)\n",
      "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Using cached pillow-10.4.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: XlsxWriter, Pillow, python-pptx\n",
      "Successfully installed Pillow-10.4.0 XlsxWriter-3.2.0 python-pptx-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.34-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.5-cp312-cp312-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_core-0.3.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.120-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.9.1-py3-none-any.whl.metadata (146 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.11.1-cp312-cp312-win_amd64.whl.metadata (49 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (4.12.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.7-cp312-none-win_amd64.whl.metadata (51 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.3 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.23.3-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.0-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sniffio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 0.8/1.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.5-cp312-cp312-win_amd64.whl (377 kB)\n",
      "Downloading langchain_core-0.3.0-py3-none-any.whl (405 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.120-py3-none-any.whl (289 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Downloading pydantic-2.9.1-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.3-cp312-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.8/1.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading SQLAlchemy-2.0.34-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.0/2.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.8/2.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "Downloading greenlet-3.1.0-cp312-cp312-win_amd64.whl (294 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached idna-3.9-py3-none-any.whl (71 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.7-cp312-none-win_amd64.whl (137 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading yarl-1.11.1-cp312-cp312-win_amd64.whl (110 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: urllib3, tenacity, sniffio, PyYAML, pydantic-core, orjson, numpy, multidict, jsonpointer, idna, h11, greenlet, frozenlist, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, aiosignal, httpx, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.34 aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.4.0 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.3.2 frozenlist-1.4.1 greenlet-3.1.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 idna-3.9 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.0 langchain-core-0.3.0 langchain-text-splitters-0.3.0 langsmith-0.1.120 multidict-6.1.0 numpy-1.26.4 orjson-3.10.7 pydantic-2.9.1 pydantic-core-2.23.3 requests-2.32.3 sniffio-1.3.1 tenacity-8.5.0 urllib3-2.2.3 yarl-1.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain_communityNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain_community) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain_community) (3.10.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain_community) (0.3.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain_community) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain_community) (0.1.120)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\projects\\genai\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\projects\\genai\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.11.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain<0.4.0,>=0.3.0->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain<0.4.0,>=0.3.0->langchain_community) (2.9.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (3.10.7)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\projects\\genai\\myenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.0)\n",
      "Requirement already satisfied: anyio in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\projects\\genai\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in e:\\projects\\genai\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain_community) (2.23.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.3 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.0 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
      "Collecting langchain_google_genai\n",
      "  Downloading langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain_google_genai)\n",
      "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain_google_genai) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3,>=2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain_google_genai) (2.9.1)\n",
      "Collecting google-ai-generativelanguage==0.6.6 (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading google_api_core-2.19.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading google_api_python_client-2.145.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting protobuf (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading protobuf-5.28.1-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting tqdm (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions in e:\\projects\\genai\\myenv\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Using cached protobuf-4.25.4-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.117 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (0.1.120)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (24.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (8.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in e:\\projects\\genai\\myenv\\lib\\site-packages (from pydantic<3,>=2->langchain_google_genai) (2.23.3)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.32.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\projects\\genai\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_google_genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (3.10.7)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: colorama in e:\\projects\\genai\\myenv\\lib\\site-packages (from tqdm->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.4.6)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Using cached grpcio-1.66.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Using cached pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: anyio in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (4.4.0)\n",
      "Requirement already satisfied: certifi in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (1.0.5)\n",
      "Requirement already satisfied: idna in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (3.9)\n",
      "Requirement already satisfied: sniffio in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (0.14.0)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.2.3)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
      "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "Downloading langchain_google_genai-2.0.0-py3-none-any.whl (39 kB)\n",
      "Downloading google_generativeai-0.7.2-py3-none-any.whl (164 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl (718 kB)\n",
      "   ---------------------------------------- 0.0/718.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 718.3/718.3 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.2-py3-none-any.whl (139 kB)\n",
      "Downloading google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "Using cached protobuf-4.25.4-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading google_api_python_client-2.145.0-py2.py3-none-any.whl (12.2 MB)\n",
      "   ---------------------------------------- 0.0/12.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.2 MB 4.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/12.2 MB 4.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.9/12.2 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.7/12.2 MB 4.0 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.7/12.2 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.5/12.2 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.3/12.2 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.8/12.2 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.9/12.2 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.7/12.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.3/12.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.2/12.2 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Using cached grpcio-1.66.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Downloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Installing collected packages: uritemplate, tqdm, pyparsing, pyasn1, protobuf, grpcio, cachetools, rsa, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai, langchain_google_genai\n",
      "Successfully installed cachetools-5.5.0 google-ai-generativelanguage-0.6.6 google-api-core-2.19.2 google-api-python-client-2.145.0 google-auth-2.34.0 google-auth-httplib2-0.2.0 google-generativeai-0.7.2 googleapis-common-protos-1.65.0 grpcio-1.66.1 grpcio-status-1.62.3 httplib2-0.22.0 langchain_google_genai-2.0.0 proto-plus-1.24.0 protobuf-4.25.4 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyparsing-3.1.4 rsa-4.9 tqdm-4.66.5 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_text_splitters in e:\\projects\\genai\\myenv\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain_text_splitters) (0.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.117 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (0.1.120)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (2.9.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\projects\\genai\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in e:\\projects\\genai\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (2.23.3)\n",
      "Requirement already satisfied: anyio in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (4.4.0)\n",
      "Requirement already satisfied: certifi in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (1.0.5)\n",
      "Requirement already satisfied: idna in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (3.9)\n",
      "Requirement already satisfied: sniffio in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.1.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting transformers<5.0.0,>=4.38.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in e:\\projects\\genai\\myenv\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.4.1-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: numpy<2.0.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.19.3 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in e:\\projects\\genai\\myenv\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Collecting filelock (from huggingface-hub>=0.19.3->sentence-transformers)\n",
      "  Downloading filelock-3.16.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.19.3->sentence-transformers)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in e:\\projects\\genai\\myenv\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\projects\\genai\\myenv\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in e:\\projects\\genai\\myenv\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\projects\\genai\\myenv\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
      "Collecting sympy (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached setuptools-74.1.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: colorama in e:\\projects\\genai\\myenv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.38.0->sentence-transformers)\n",
      "  Downloading regex-2024.9.11-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.38.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.38.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2024.8.30)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading sentence_transformers-3.1.0-py3-none-any.whl (249 kB)\n",
      "Downloading huggingface_hub-0.24.7-py3-none-any.whl (417 kB)\n",
      "Downloading torch-2.4.1-cp312-cp312-win_amd64.whl (199.4 MB)\n",
      "   ---------------------------------------- 0.0/199.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/199.4 MB 5.6 MB/s eta 0:00:36\n",
      "   ---------------------------------------- 1.8/199.4 MB 4.4 MB/s eta 0:00:46\n",
      "    --------------------------------------- 2.9/199.4 MB 4.1 MB/s eta 0:00:48\n",
      "    --------------------------------------- 3.7/199.4 MB 4.0 MB/s eta 0:00:49\n",
      "    --------------------------------------- 4.5/199.4 MB 4.1 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 5.2/199.4 MB 4.0 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 6.0/199.4 MB 4.0 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 7.1/199.4 MB 4.0 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 7.9/199.4 MB 4.0 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 8.7/199.4 MB 3.9 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 9.4/199.4 MB 3.9 MB/s eta 0:00:49\n",
      "   -- ------------------------------------- 10.5/199.4 MB 3.9 MB/s eta 0:00:48\n",
      "   -- ------------------------------------- 11.3/199.4 MB 3.9 MB/s eta 0:00:48\n",
      "   -- ------------------------------------- 12.1/199.4 MB 3.9 MB/s eta 0:00:48\n",
      "   -- ------------------------------------- 12.8/199.4 MB 3.9 MB/s eta 0:00:48\n",
      "   -- ------------------------------------- 13.6/199.4 MB 3.9 MB/s eta 0:00:48\n",
      "   -- ------------------------------------- 14.7/199.4 MB 3.9 MB/s eta 0:00:48\n",
      "   --- ------------------------------------ 15.5/199.4 MB 3.9 MB/s eta 0:00:48\n",
      "   --- ------------------------------------ 16.3/199.4 MB 3.9 MB/s eta 0:00:47\n",
      "   --- ------------------------------------ 17.0/199.4 MB 3.9 MB/s eta 0:00:47\n",
      "   --- ------------------------------------ 18.1/199.4 MB 3.9 MB/s eta 0:00:47\n",
      "   --- ------------------------------------ 18.9/199.4 MB 3.9 MB/s eta 0:00:47\n",
      "   --- ------------------------------------ 19.7/199.4 MB 3.9 MB/s eta 0:00:47\n",
      "   ---- ----------------------------------- 20.4/199.4 MB 3.9 MB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 21.2/199.4 MB 3.9 MB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 22.3/199.4 MB 3.9 MB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 23.1/199.4 MB 3.9 MB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 23.9/199.4 MB 3.9 MB/s eta 0:00:45\n",
      "   ---- ----------------------------------- 24.6/199.4 MB 3.9 MB/s eta 0:00:45\n",
      "   ----- ---------------------------------- 25.4/199.4 MB 3.9 MB/s eta 0:00:45\n",
      "   ----- ---------------------------------- 26.5/199.4 MB 3.9 MB/s eta 0:00:45\n",
      "   ----- ---------------------------------- 27.3/199.4 MB 3.9 MB/s eta 0:00:45\n",
      "   ----- ---------------------------------- 28.0/199.4 MB 3.9 MB/s eta 0:00:44\n",
      "   ----- ---------------------------------- 28.8/199.4 MB 3.9 MB/s eta 0:00:44\n",
      "   ----- ---------------------------------- 29.9/199.4 MB 3.9 MB/s eta 0:00:44\n",
      "   ------ --------------------------------- 30.7/199.4 MB 3.9 MB/s eta 0:00:44\n",
      "   ------ --------------------------------- 31.5/199.4 MB 3.9 MB/s eta 0:00:44\n",
      "   ------ --------------------------------- 32.2/199.4 MB 3.9 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 33.3/199.4 MB 3.9 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 34.1/199.4 MB 3.9 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 34.9/199.4 MB 3.9 MB/s eta 0:00:43\n",
      "   ------- -------------------------------- 35.7/199.4 MB 3.9 MB/s eta 0:00:43\n",
      "   ------- -------------------------------- 36.7/199.4 MB 3.9 MB/s eta 0:00:42\n",
      "   ------- -------------------------------- 37.5/199.4 MB 3.9 MB/s eta 0:00:42\n",
      "   ------- -------------------------------- 38.3/199.4 MB 3.9 MB/s eta 0:00:42\n",
      "   ------- -------------------------------- 39.1/199.4 MB 3.9 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 40.1/199.4 MB 3.9 MB/s eta 0:00:41\n",
      "   -------- ------------------------------- 40.9/199.4 MB 3.9 MB/s eta 0:00:41\n",
      "   -------- ------------------------------- 41.4/199.4 MB 3.9 MB/s eta 0:00:41\n",
      "   -------- ------------------------------- 42.5/199.4 MB 3.9 MB/s eta 0:00:41\n",
      "   -------- ------------------------------- 43.3/199.4 MB 3.9 MB/s eta 0:00:41\n",
      "   -------- ------------------------------- 44.3/199.4 MB 3.9 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 45.1/199.4 MB 3.9 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 45.9/199.4 MB 3.9 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 46.7/199.4 MB 3.9 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 47.7/199.4 MB 3.9 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 48.5/199.4 MB 3.9 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 49.3/199.4 MB 3.9 MB/s eta 0:00:39\n",
      "   ---------- ----------------------------- 50.3/199.4 MB 3.9 MB/s eta 0:00:39\n",
      "   ---------- ----------------------------- 51.1/199.4 MB 3.9 MB/s eta 0:00:39\n",
      "   ---------- ----------------------------- 51.9/199.4 MB 3.9 MB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 52.7/199.4 MB 3.9 MB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 53.7/199.4 MB 3.9 MB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 54.5/199.4 MB 3.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 55.3/199.4 MB 3.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 56.1/199.4 MB 3.9 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 57.1/199.4 MB 3.9 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 57.9/199.4 MB 3.9 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 58.7/199.4 MB 3.9 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 59.5/199.4 MB 3.9 MB/s eta 0:00:37\n",
      "   ------------ --------------------------- 60.6/199.4 MB 3.9 MB/s eta 0:00:36\n",
      "   ------------ --------------------------- 61.3/199.4 MB 3.9 MB/s eta 0:00:36\n",
      "   ------------ --------------------------- 62.1/199.4 MB 3.9 MB/s eta 0:00:36\n",
      "   ------------ --------------------------- 62.9/199.4 MB 3.9 MB/s eta 0:00:36\n",
      "   ------------ --------------------------- 64.0/199.4 MB 3.9 MB/s eta 0:00:35\n",
      "   ------------ --------------------------- 64.7/199.4 MB 3.9 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 65.5/199.4 MB 3.9 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 66.6/199.4 MB 3.9 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 67.4/199.4 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 68.2/199.4 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 68.9/199.4 MB 3.9 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 69.7/199.4 MB 3.9 MB/s eta 0:00:34\n",
      "   -------------- ------------------------- 70.8/199.4 MB 3.9 MB/s eta 0:00:34\n",
      "   -------------- ------------------------- 71.6/199.4 MB 3.9 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 72.4/199.4 MB 3.9 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 73.1/199.4 MB 3.9 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 73.9/199.4 MB 3.9 MB/s eta 0:00:33\n",
      "   --------------- ------------------------ 75.0/199.4 MB 3.9 MB/s eta 0:00:33\n",
      "   --------------- ------------------------ 75.8/199.4 MB 3.9 MB/s eta 0:00:32\n",
      "   --------------- ------------------------ 76.5/199.4 MB 3.9 MB/s eta 0:00:32\n",
      "   --------------- ------------------------ 77.3/199.4 MB 3.9 MB/s eta 0:00:32\n",
      "   --------------- ------------------------ 78.1/199.4 MB 3.9 MB/s eta 0:00:32\n",
      "   --------------- ------------------------ 78.9/199.4 MB 3.9 MB/s eta 0:00:32\n",
      "   ---------------- ----------------------- 80.0/199.4 MB 3.9 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 80.7/199.4 MB 3.9 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 81.5/199.4 MB 3.9 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 82.3/199.4 MB 3.9 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 83.4/199.4 MB 3.9 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 84.1/199.4 MB 3.9 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 84.9/199.4 MB 3.9 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 85.7/199.4 MB 3.9 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 86.5/199.4 MB 3.9 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 87.3/199.4 MB 3.9 MB/s eta 0:00:29\n",
      "   ----------------- ---------------------- 88.3/199.4 MB 3.9 MB/s eta 0:00:29\n",
      "   ----------------- ---------------------- 89.1/199.4 MB 3.9 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 89.9/199.4 MB 3.9 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 90.7/199.4 MB 3.9 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 91.8/199.4 MB 3.9 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 92.5/199.4 MB 3.9 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 93.3/199.4 MB 3.9 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 94.1/199.4 MB 3.9 MB/s eta 0:00:28\n",
      "   ------------------- -------------------- 94.9/199.4 MB 3.9 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 95.7/199.4 MB 3.9 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 96.7/199.4 MB 3.9 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 97.5/199.4 MB 3.9 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 98.3/199.4 MB 3.9 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 99.1/199.4 MB 3.9 MB/s eta 0:00:26\n",
      "   -------------------- ------------------- 99.9/199.4 MB 3.9 MB/s eta 0:00:26\n",
      "   -------------------- ------------------- 100.7/199.4 MB 3.9 MB/s eta 0:00:26\n",
      "   -------------------- ------------------- 101.7/199.4 MB 3.9 MB/s eta 0:00:26\n",
      "   -------------------- ------------------- 102.5/199.4 MB 3.9 MB/s eta 0:00:25\n",
      "   -------------------- ------------------- 103.3/199.4 MB 3.9 MB/s eta 0:00:25\n",
      "   -------------------- ------------------- 104.1/199.4 MB 3.9 MB/s eta 0:00:25\n",
      "   --------------------- ------------------ 104.9/199.4 MB 3.9 MB/s eta 0:00:25\n",
      "   --------------------- ------------------ 105.9/199.4 MB 3.9 MB/s eta 0:00:25\n",
      "   --------------------- ------------------ 106.2/199.4 MB 3.9 MB/s eta 0:00:25\n",
      "   --------------------- ------------------ 107.2/199.4 MB 3.9 MB/s eta 0:00:24\n",
      "   --------------------- ------------------ 107.2/199.4 MB 3.9 MB/s eta 0:00:24\n",
      "   --------------------- ------------------ 107.7/199.4 MB 3.8 MB/s eta 0:00:24\n",
      "   --------------------- ------------------ 108.0/199.4 MB 3.8 MB/s eta 0:00:24\n",
      "   --------------------- ------------------ 108.3/199.4 MB 3.8 MB/s eta 0:00:24\n",
      "   --------------------- ------------------ 108.5/199.4 MB 3.8 MB/s eta 0:00:25\n",
      "   --------------------- ------------------ 109.1/199.4 MB 3.8 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 109.8/199.4 MB 3.8 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 110.6/199.4 MB 3.8 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 111.4/199.4 MB 3.8 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 112.2/199.4 MB 3.8 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 113.2/199.4 MB 3.8 MB/s eta 0:00:23\n",
      "   ---------------------- ----------------- 114.0/199.4 MB 3.8 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 114.8/199.4 MB 3.8 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 115.6/199.4 MB 3.8 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 116.4/199.4 MB 3.8 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 117.4/199.4 MB 3.8 MB/s eta 0:00:22\n",
      "   ----------------------- ---------------- 118.2/199.4 MB 3.8 MB/s eta 0:00:22\n",
      "   ----------------------- ---------------- 119.0/199.4 MB 3.8 MB/s eta 0:00:22\n",
      "   ----------------------- ---------------- 119.5/199.4 MB 3.8 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 120.6/199.4 MB 3.7 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 121.4/199.4 MB 3.7 MB/s eta 0:00:21\n",
      "   ------------------------ --------------- 122.2/199.4 MB 3.7 MB/s eta 0:00:21\n",
      "   ------------------------ --------------- 122.9/199.4 MB 3.7 MB/s eta 0:00:21\n",
      "   ------------------------ --------------- 123.7/199.4 MB 3.7 MB/s eta 0:00:21\n",
      "   ------------------------ --------------- 124.5/199.4 MB 3.7 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 125.6/199.4 MB 3.7 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 126.4/199.4 MB 3.7 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 127.1/199.4 MB 3.7 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 127.9/199.4 MB 3.7 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 128.7/199.4 MB 3.7 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 129.8/199.4 MB 3.8 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 130.5/199.4 MB 3.7 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 131.3/199.4 MB 3.7 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 132.1/199.4 MB 3.7 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 132.9/199.4 MB 3.7 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 134.0/199.4 MB 3.7 MB/s eta 0:00:18\n",
      "   --------------------------- ------------ 134.7/199.4 MB 3.7 MB/s eta 0:00:18\n",
      "   --------------------------- ------------ 135.5/199.4 MB 3.7 MB/s eta 0:00:18\n",
      "   --------------------------- ------------ 136.6/199.4 MB 3.7 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 137.4/199.4 MB 3.7 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 138.1/199.4 MB 3.7 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 138.9/199.4 MB 3.7 MB/s eta 0:00:17\n",
      "   ---------------------------- ----------- 139.7/199.4 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 140.8/199.4 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 141.6/199.4 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 142.3/199.4 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 143.1/199.4 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 143.9/199.4 MB 3.7 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 144.7/199.4 MB 3.7 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 145.8/199.4 MB 3.7 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 146.5/199.4 MB 3.7 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 147.6/199.4 MB 3.7 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 148.4/199.4 MB 3.7 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 149.2/199.4 MB 3.7 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 149.9/199.4 MB 3.7 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 151.0/199.4 MB 3.7 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 151.8/199.4 MB 3.7 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 152.6/199.4 MB 3.7 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 153.6/199.4 MB 3.7 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 154.4/199.4 MB 3.8 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 155.2/199.4 MB 3.7 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 156.0/199.4 MB 3.7 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 156.8/199.4 MB 3.7 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 157.8/199.4 MB 3.7 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 158.6/199.4 MB 3.7 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 159.4/199.4 MB 3.7 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 160.2/199.4 MB 3.7 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 161.2/199.4 MB 3.7 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 162.0/199.4 MB 3.7 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 162.8/199.4 MB 3.7 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 163.8/199.4 MB 3.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 164.6/199.4 MB 3.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 165.4/199.4 MB 3.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 166.2/199.4 MB 3.7 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 167.2/199.4 MB 3.7 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 168.3/199.4 MB 3.8 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 169.1/199.4 MB 3.7 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 169.9/199.4 MB 3.7 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 170.7/199.4 MB 3.7 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 171.4/199.4 MB 3.7 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 172.5/199.4 MB 3.7 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 173.3/199.4 MB 3.7 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 174.1/199.4 MB 3.7 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 174.9/199.4 MB 3.7 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 175.6/199.4 MB 3.7 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 176.7/199.4 MB 3.7 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 177.5/199.4 MB 3.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 178.3/199.4 MB 3.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 179.0/199.4 MB 3.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 179.8/199.4 MB 3.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 180.9/199.4 MB 3.7 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 181.7/199.4 MB 3.7 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 182.5/199.4 MB 3.7 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 183.2/199.4 MB 3.7 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 184.0/199.4 MB 3.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 184.8/199.4 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 185.9/199.4 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 186.6/199.4 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 187.4/199.4 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 188.2/199.4 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 189.0/199.4 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 189.8/199.4 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 190.6/199.4 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 191.6/199.4 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 192.4/199.4 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 193.2/199.4 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 194.0/199.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------------------  194.8/199.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.6/199.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.6/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.4/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.2/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.0/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.4/199.4 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/9.5 MB 5.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.8/9.5 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.9/9.5 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.7/9.5 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.5/9.5 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.2/9.5 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.0/9.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.8/9.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.3/9.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 3.7 MB/s eta 0:00:00\n",
      "Using cached scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading regex-2024.9.11-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.0/2.2 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading filelock-3.16.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.0/1.7 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.7 MB/s eta 0:00:00\n",
      "Using cached setuptools-74.1.2-py3-none-any.whl (1.3 MB)\n",
      "Downloading sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.2 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.9/6.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.7/6.2 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.2 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 3.6 MB/s eta 0:00:00\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 4.4 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, setuptools, scipy, safetensors, regex, networkx, MarkupSafe, joblib, fsspec, filelock, scikit-learn, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.16.0 fsspec-2024.9.0 huggingface-hub-0.24.7 jinja2-3.1.4 joblib-1.4.2 mpmath-1.3.0 networkx-3.3 regex-2024.9.11 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 sentence-transformers-3.1.0 setuptools-74.1.2 sympy-1.13.2 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.4.1 transformers-4.44.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting faiss-cpuNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in e:\\projects\\genai\\myenv\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl (14.6 MB)\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/14.6 MB 8.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.8/14.6 MB 4.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.6/14.6 MB 4.4 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.1/14.6 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.5/14.6 MB 4.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.2/14.6 MB 4.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.0/14.6 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.8/14.6 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.6/14.6 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.4/14.6 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.4/14.6 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.2/14.6 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.0/14.6 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.8/14.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.6 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.6/14.6 MB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n",
      "Collecting cohere\n",
      "  Downloading cohere-5.9.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting boto3<2.0.0,>=1.34.0 (from cohere)\n",
      "  Downloading boto3-1.35.19-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
      "  Downloading fastavro-1.9.7-cp312-cp312-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: httpx>=0.21.2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from cohere) (0.27.2)\n",
      "Collecting httpx-sse==0.4.0 (from cohere)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from cohere) (2.9.1)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from cohere) (2.23.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from cohere) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in e:\\projects\\genai\\myenv\\lib\\site-packages (from cohere) (0.19.1)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
      "  Downloading types_requests-2.32.0.20240914-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from cohere) (4.12.2)\n",
      "Collecting botocore<1.36.0,>=1.35.19 (from boto3<2.0.0,>=1.34.0->cohere)\n",
      "  Downloading botocore-1.35.19-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere)\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: anyio in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx>=0.21.2->cohere) (4.4.0)\n",
      "Requirement already satisfied: certifi in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.0.5)\n",
      "Requirement already satisfied: idna in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx>=0.21.2->cohere) (3.9)\n",
      "Requirement already satisfied: sniffio in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\projects\\genai\\myenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\projects\\genai\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in e:\\projects\\genai\\myenv\\lib\\site-packages (from tokenizers<1,>=0.15->cohere) (0.24.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in e:\\projects\\genai\\myenv\\lib\\site-packages (from botocore<1.36.0,>=1.35.19->boto3<2.0.0,>=1.34.0->cohere) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in e:\\projects\\genai\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\projects\\genai\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in e:\\projects\\genai\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\projects\\genai\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in e:\\projects\\genai\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.5)\n",
      "Requirement already satisfied: six>=1.5 in e:\\projects\\genai\\myenv\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.19->boto3<2.0.0,>=1.34.0->cohere) (1.16.0)\n",
      "Requirement already satisfied: colorama in e:\\projects\\genai\\myenv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (0.4.6)\n",
      "Downloading cohere-5.9.2-py3-none-any.whl (222 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading boto3-1.35.19-py3-none-any.whl (139 kB)\n",
      "Downloading fastavro-1.9.7-cp312-cp312-win_amd64.whl (487 kB)\n",
      "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading types_requests-2.32.0.20240914-py3-none-any.whl (15 kB)\n",
      "Downloading botocore-1.35.19-py3-none-any.whl (12.5 MB)\n",
      "   ---------------------------------------- 0.0/12.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.5 MB 5.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/12.5 MB 3.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.6/12.5 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.7/12.5 MB 4.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.5/12.5 MB 4.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.2/12.5 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.0/12.5 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.8/12.5 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.9/12.5 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.7/12.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.4/12.5 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.2/12.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.0/12.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.5/12.5 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "Installing collected packages: types-requests, parameterized, jmespath, httpx-sse, fastavro, botocore, s3transfer, boto3, cohere\n",
      "Successfully installed boto3-1.35.19 botocore-1.35.19 cohere-5.9.2 fastavro-1.9.7 httpx-sse-0.4.0 jmespath-1.0.1 parameterized-0.9.0 s3transfer-0.10.2 types-requests-2.32.0.20240914\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-docx\n",
    "%pip install python-pptx\n",
    "%pip install PyPDF2\n",
    "%pip install langchain\n",
    "%pip install langchain_community\n",
    "%pip install langchain_google_genai\n",
    "%pip install langchain_text_splitters\n",
    "%pip install sentence-transformers\n",
    "%pip install faiss-cpu\n",
    "%pip install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "pdf_file = open(r'E:\\PROJECTS\\GenAI\\Vaibhav Sharma Resume.pdf','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedReader name='E:\\\\PROJECTS\\\\GenAI\\\\Vaibhav Sharma Resume.pdf'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = \"\"\n",
    "pdf_reader = PdfReader(pdf_file)\n",
    "for page in pdf_reader.pages:\n",
    "    pdf_text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaibhav\n",
      "Sharma\n",
      "Data\n",
      "Science\n",
      "/\n",
      "Machine\n",
      "Learning\n",
      "vaibhavshrma002@gmail.com\n",
      "|\n",
      "github.com/vaibhv02\n",
      "|\n",
      "linkedin.com/in/er-vaibhav-sharma\n",
      "|\n",
      "+91-7018747685\n",
      "Aspiring\n",
      "Data\n",
      "Science\n",
      "Engineer\n",
      "currently\n",
      "in\n",
      "final\n",
      "year\n",
      "of\n",
      "B.Tech\n",
      "in\n",
      "Computer\n",
      "Science\n",
      "and\n",
      "Engineering\n",
      "at\n",
      "Rayat\n",
      "Bahara \n",
      "University.\n",
      "Skilled\n",
      "in\n",
      "data\n",
      "analysis,\n",
      "machine\n",
      "learning,\n",
      "and\n",
      "software\n",
      "development.\n",
      "Keen\n",
      "interest\n",
      "in\n",
      "applying\n",
      "knowledge\n",
      "to \n",
      "practical\n",
      "challenges.\n",
      "Seeking\n",
      "an\n",
      "internship\n",
      "to\n",
      "gain\n",
      "hands-on\n",
      "experience\n",
      "and\n",
      "contribute\n",
      "to\n",
      "innovative\n",
      "projects.\n",
      "Projects\n",
      "Twitter\n",
      "sentiment\n",
      "Analysis\n",
      "\n",
      "Built\n",
      "a\n",
      "machine\n",
      "learning\n",
      "model\n",
      "to\n",
      "classify\n",
      "1.6\n",
      "million\n",
      "tweets\n",
      "from\n",
      "the\n",
      "Sentiment\n",
      "dataset. \n",
      "\n",
      "Pre-processed\n",
      "data\n",
      "by\n",
      "cleaning\n",
      "text\n",
      "and\n",
      "using\n",
      "vectorization;\n",
      "trained\n",
      "a\n",
      "Logistic\n",
      "Regression\n",
      "model. \n",
      "\n",
      "Achieved\n",
      "high\n",
      "accuracy\n",
      "and\n",
      "robust\n",
      "performance,\n",
      "gaining\n",
      "insights\n",
      "into\n",
      "public\n",
      "sentiment\n",
      "across\n",
      "various\n",
      "topics.\n",
      "Customer\n",
      "Segmentation\n",
      "and\n",
      "Predictive\n",
      "Analytics\n",
      "\n",
      "Applied\n",
      "K-Means\n",
      "clustering\n",
      "to\n",
      "segment\n",
      "customers\n",
      "based\n",
      "on\n",
      "buying\n",
      "behavior. \n",
      "\n",
      "Extracted\n",
      "meaningful\n",
      "insights\n",
      "from\n",
      "complex\n",
      "customer\n",
      "data\n",
      "with\n",
      "thorough\n",
      "data\n",
      "cleaning\n",
      "and\n",
      "feature\n",
      "engineering. \n",
      "\n",
      "Optimized\n",
      "marketing\n",
      "strategies\n",
      "through\n",
      "iterative\n",
      "model\n",
      "refinement.\n",
      "Predicting\n",
      "Housing\n",
      "Prices\n",
      "in\n",
      "California\n",
      "\n",
      "Predicted\n",
      "housing\n",
      "prices\n",
      "using\n",
      "Linear\n",
      "Regression\n",
      "and\n",
      "Random\n",
      "Forest\n",
      "models. \n",
      "\n",
      "Handled\n",
      "categorical\n",
      "variables\n",
      "and\n",
      "large-scale\n",
      "data\n",
      "preprocessing\n",
      "effectively. \n",
      "\n",
      "Achieved\n",
      "accurate\n",
      "price\n",
      "predictions\n",
      "through\n",
      "robust\n",
      "preprocessing\n",
      "and\n",
      "ensemble\n",
      "modeling.\n",
      "Object\n",
      "Detection\n",
      "in\n",
      "Real\n",
      "Time\n",
      "Video\n",
      "Stream\n",
      "\n",
      "Developed\n",
      "a\n",
      "real-time\n",
      "object\n",
      "detection\n",
      "application\n",
      "using\n",
      "YOLOv3\n",
      "and\n",
      "OpenCV. \n",
      "\n",
      "Implement\n",
      "efficient\n",
      "frame\n",
      "processing\n",
      "and\n",
      "visualization\n",
      "for\n",
      "live\n",
      "object\n",
      "classification. \n",
      "\n",
      "Optimized\n",
      "system\n",
      "performance\n",
      "with\n",
      "adjustable\n",
      "model\n",
      "parameters\n",
      "and\n",
      "real-time\n",
      "display.\n",
      "Education\n",
      "B.Tech\n",
      "-\n",
      "Computer\n",
      "Science\n",
      "Engineering\n",
      "(06/21\n",
      "-\n",
      "06/25)\n",
      "Rayat\n",
      "Bahara\n",
      "University,\n",
      "Punjab\n",
      "Professional\n",
      "Certifications\n",
      "\n",
      "IBM\n",
      "Data\n",
      "Science\n",
      "Professional\n",
      "Certificate \n",
      "\n",
      "Machine\n",
      "Learning\n",
      "and\n",
      "Deep\n",
      "Learning\n",
      "-\n",
      "Fundamentals\n",
      "and\n",
      "Applications\n",
      "(NPTEL) \n",
      "\n",
      "Full\n",
      "Stack\n",
      "Development\n",
      "Program\n",
      "(Excellence\n",
      "Education) \n",
      "\n",
      "Full\n",
      "Stack\n",
      "Web\n",
      "Development\n",
      "(MCP\n",
      "Technology)\n",
      "Skills\n",
      "&\n",
      "abilities\n",
      "Data\n",
      "Analysis\n",
      "and\n",
      "Machine\n",
      "Learning:\n",
      "Data\n",
      "Cleaning,\n",
      "Data\n",
      "Preprocessing,\n",
      "Pandas,\n",
      "Numpy,\n",
      "Statistics,\n",
      "Linear \n",
      "Regression,\n",
      "k-means\n",
      "Clustering,\n",
      "Random\n",
      "Forest,\n",
      "Scikit-Learn,\n",
      "Feature\n",
      "Engineering,\n",
      "Model\n",
      "Evaluation,\n",
      "Predictive \n",
      "Modeling,\n",
      "Deep\n",
      "learning\n",
      "techniques,\n",
      "YOLOv3\n",
      "(You\n",
      "Look\n",
      "Only\n",
      "Once)\n",
      "Data\n",
      "Management\n",
      "and\n",
      "Visualization:\n",
      "Data\n",
      "visualization,\n",
      "Matplotlib,\n",
      "Large\n",
      "datasets,\n",
      "MySQL,\n",
      "MongoDB,\n",
      "DBMS,\n",
      "Jupyter \n",
      "Notebook,\n",
      "OpenCV.\n",
      "Programming\n",
      "and\n",
      "Tools:\n",
      "Python,\n",
      "Git\n",
      "Soft\n",
      "Skills:\n",
      "Problem\n",
      "Solving,\n",
      "Communication\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# splitting the text into chunks for embeddings creation\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1000, \n",
    "        chunk_overlap = 200, # This is helpul to handle the data loss while chunking.\n",
    "        length_function = len,\n",
    "        separators=['\\n\\n', ' ', '']\n",
    "    )\n",
    "    \n",
    "chunks = text_splitter.split_text(text = pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vaibhav\\nSharma\\nData\\nScience\\n/\\nMachine\\nLearning\\nvaibhavshrma002@gmail.com\\n|\\ngithub.com/vaibhv02\\n|\\nlinkedin.com/in/er-vaibhav-sharma\\n|\\n+91-7018747685\\nAspiring\\nData\\nScience\\nEngineer\\ncurrently\\nin\\nfinal\\nyear\\nof\\nB.Tech\\nin\\nComputer\\nScience\\nand\\nEngineering\\nat\\nRayat\\nBahara \\nUniversity.\\nSkilled\\nin\\ndata\\nanalysis,\\nmachine\\nlearning,\\nand\\nsoftware\\ndevelopment.\\nKeen\\ninterest\\nin\\napplying\\nknowledge\\nto \\npractical\\nchallenges.\\nSeeking\\nan\\ninternship\\nto\\ngain\\nhands-on\\nexperience\\nand\\ncontribute\\nto\\ninnovative\\nprojects.\\nProjects\\nTwitter\\nsentiment\\nAnalysis\\n\\nBuilt\\na\\nmachine\\nlearning\\nmodel\\nto\\nclassify\\n1.6\\nmillion\\ntweets\\nfrom\\nthe\\nSentiment\\ndataset. \\n\\nPre-processed\\ndata\\nby\\ncleaning\\ntext\\nand\\nusing\\nvectorization;\\ntrained\\na\\nLogistic\\nRegression\\nmodel. \\n\\nAchieved\\nhigh\\naccuracy\\nand\\nrobust\\nperformance,\\ngaining\\ninsights\\ninto\\npublic\\nsentiment\\nacross\\nvarious\\ntopics.\\nCustomer\\nSegmentation\\nand\\nPredictive\\nAnalytics\\n\\nApplied\\nK-Means\\nclustering\\nto\\nsegment\\ncustomers\\nbased\\non\\nbuying\\nbehavior.',\n",
       " '\\nExtracted\\nmeaningful\\ninsights\\nfrom\\ncomplex\\ncustomer\\ndata\\nwith\\nthorough\\ndata\\ncleaning\\nand\\nfeature\\nengineering. \\n\\nOptimized\\nmarketing\\nstrategies\\nthrough\\niterative\\nmodel\\nrefinement.\\nPredicting\\nHousing\\nPrices\\nin\\nCalifornia\\n\\nPredicted\\nhousing\\nprices\\nusing\\nLinear\\nRegression\\nand\\nRandom\\nForest\\nmodels. \\n\\nHandled\\ncategorical\\nvariables\\nand\\nlarge-scale\\ndata\\npreprocessing\\neffectively. \\n\\nAchieved\\naccurate\\nprice\\npredictions\\nthrough\\nrobust\\npreprocessing\\nand\\nensemble\\nmodeling.\\nObject\\nDetection\\nin\\nReal\\nTime\\nVideo\\nStream\\n\\nDeveloped\\na\\nreal-time\\nobject\\ndetection\\napplication\\nusing\\nYOLOv3\\nand\\nOpenCV. \\n\\nImplement\\nefficient\\nframe\\nprocessing\\nand\\nvisualization\\nfor\\nlive\\nobject\\nclassification. \\n\\nOptimized\\nsystem\\nperformance\\nwith\\nadjustable\\nmodel\\nparameters\\nand\\nreal-time\\ndisplay.\\nEducation\\nB.Tech\\n-\\nComputer\\nScience\\nEngineering\\n(06/21\\n-\\n06/25)\\nRayat\\nBahara\\nUniversity,\\nPunjab\\nProfessional\\nCertifications\\n\\nIBM\\nData\\nScience\\nProfessional\\nCertificate',\n",
       " '\\nMachine\\nLearning\\nand\\nDeep\\nLearning\\n-\\nFundamentals\\nand\\nApplications\\n(NPTEL) \\n\\nFull\\nStack\\nDevelopment\\nProgram\\n(Excellence\\nEducation) \\n\\nFull\\nStack\\nWeb\\nDevelopment\\n(MCP\\nTechnology)\\nSkills\\n&\\nabilities\\nData\\nAnalysis\\nand\\nMachine\\nLearning:\\nData\\nCleaning,\\nData\\nPreprocessing,\\nPandas,\\nNumpy,\\nStatistics,\\nLinear \\nRegression,\\nk-means\\nClustering,\\nRandom\\nForest,\\nScikit-Learn,\\nFeature\\nEngineering,\\nModel\\nEvaluation,\\nPredictive \\nModeling,\\nDeep\\nlearning\\ntechniques,\\nYOLOv3\\n(You\\nLook\\nOnly\\nOnce)\\nData\\nManagement\\nand\\nVisualization:\\nData\\nvisualization,\\nMatplotlib,\\nLarge\\ndatasets,\\nMySQL,\\nMongoDB,\\nDBMS,\\nJupyter \\nNotebook,\\nOpenCV.\\nProgramming\\nand\\nTools:\\nPython,\\nGit\\nSoft\\nSkills:\\nProblem\\nSolving,\\nCommunication']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PROJECTS\\GenAI\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24360\\3239463429.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "e:\\PROJECTS\\GenAI\\myenv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "e:\\PROJECTS\\GenAI\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "e:\\PROJECTS\\GenAI\\myenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initializing embeddings model\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Indexing the data using FAISS\n",
    "vectorstore = FAISS.from_texts(chunks, embedding = embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x15ef6054440>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000015EF6054440>, search_kwargs={'k': 2})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is the name of the college?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='\\nMachine\\nLearning\\nand\\nDeep\\nLearning\\n-\\nFundamentals\\nand\\nApplications\\n(NPTEL) \\n\\nFull\\nStack\\nDevelopment\\nProgram\\n(Excellence\\nEducation) \\n\\nFull\\nStack\\nWeb\\nDevelopment\\n(MCP\\nTechnology)\\nSkills\\n&\\nabilities\\nData\\nAnalysis\\nand\\nMachine\\nLearning:\\nData\\nCleaning,\\nData\\nPreprocessing,\\nPandas,\\nNumpy,\\nStatistics,\\nLinear \\nRegression,\\nk-means\\nClustering,\\nRandom\\nForest,\\nScikit-Learn,\\nFeature\\nEngineering,\\nModel\\nEvaluation,\\nPredictive \\nModeling,\\nDeep\\nlearning\\ntechniques,\\nYOLOv3\\n(You\\nLook\\nOnly\\nOnce)\\nData\\nManagement\\nand\\nVisualization:\\nData\\nvisualization,\\nMatplotlib,\\nLarge\\ndatasets,\\nMySQL,\\nMongoDB,\\nDBMS,\\nJupyter \\nNotebook,\\nOpenCV.\\nProgramming\\nand\\nTools:\\nPython,\\nGit\\nSoft\\nSkills:\\nProblem\\nSolving,\\nCommunication'),\n",
       " Document(metadata={}, page_content='\\nExtracted\\nmeaningful\\ninsights\\nfrom\\ncomplex\\ncustomer\\ndata\\nwith\\nthorough\\ndata\\ncleaning\\nand\\nfeature\\nengineering. \\n\\nOptimized\\nmarketing\\nstrategies\\nthrough\\niterative\\nmodel\\nrefinement.\\nPredicting\\nHousing\\nPrices\\nin\\nCalifornia\\n\\nPredicted\\nhousing\\nprices\\nusing\\nLinear\\nRegression\\nand\\nRandom\\nForest\\nmodels. \\n\\nHandled\\ncategorical\\nvariables\\nand\\nlarge-scale\\ndata\\npreprocessing\\neffectively. \\n\\nAchieved\\naccurate\\nprice\\npredictions\\nthrough\\nrobust\\npreprocessing\\nand\\nensemble\\nmodeling.\\nObject\\nDetection\\nin\\nReal\\nTime\\nVideo\\nStream\\n\\nDeveloped\\na\\nreal-time\\nobject\\ndetection\\napplication\\nusing\\nYOLOv3\\nand\\nOpenCV. \\n\\nImplement\\nefficient\\nframe\\nprocessing\\nand\\nvisualization\\nfor\\nlive\\nobject\\nclassification. \\n\\nOptimized\\nsystem\\nperformance\\nwith\\nadjustable\\nmodel\\nparameters\\nand\\nreal-time\\ndisplay.\\nEducation\\nB.Tech\\n-\\nComputer\\nScience\\nEngineering\\n(06/21\\n-\\n06/25)\\nRayat\\nBahara\\nUniversity,\\nPunjab\\nProfessional\\nCertifications\\n\\nIBM\\nData\\nScience\\nProfessional\\nCertificate')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Machine\n",
      "Learning\n",
      "and\n",
      "Deep\n",
      "Learning\n",
      "-\n",
      "Fundamentals\n",
      "and\n",
      "Applications\n",
      "(NPTEL) \n",
      "\n",
      "Full\n",
      "Stack\n",
      "Development\n",
      "Program\n",
      "(Excellence\n",
      "Education) \n",
      "\n",
      "Full\n",
      "Stack\n",
      "Web\n",
      "Development\n",
      "(MCP\n",
      "Technology)\n",
      "Skills\n",
      "&\n",
      "abilities\n",
      "Data\n",
      "Analysis\n",
      "and\n",
      "Machine\n",
      "Learning:\n",
      "Data\n",
      "Cleaning,\n",
      "Data\n",
      "Preprocessing,\n",
      "Pandas,\n",
      "Numpy,\n",
      "Statistics,\n",
      "Linear \n",
      "Regression,\n",
      "k-means\n",
      "Clustering,\n",
      "Random\n",
      "Forest,\n",
      "Scikit-Learn,\n",
      "Feature\n",
      "Engineering,\n",
      "Model\n",
      "Evaluation,\n",
      "Predictive \n",
      "Modeling,\n",
      "Deep\n",
      "learning\n",
      "techniques,\n",
      "YOLOv3\n",
      "(You\n",
      "Look\n",
      "Only\n",
      "Once)\n",
      "Data\n",
      "Management\n",
      "and\n",
      "Visualization:\n",
      "Data\n",
      "visualization,\n",
      "Matplotlib,\n",
      "Large\n",
      "datasets,\n",
      "MySQL,\n",
      "MongoDB,\n",
      "DBMS,\n",
      "Jupyter \n",
      "Notebook,\n",
      "OpenCV.\n",
      "Programming\n",
      "and\n",
      "Tools:\n",
      "Python,\n",
      "Git\n",
      "Soft\n",
      "Skills:\n",
      "Problem\n",
      "Solving,\n",
      "Communication\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts  import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt_template = \"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
    "                not contained in the context, say \"answer not available in context\" \\n\\n\n",
    "                Context: \\n {context}?\\n\n",
    "                Question: \\n {question} \\n\n",
    "                Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question as precise as possible using the provided context. If the answer is\\n                not contained in the context, say \"answer not available in context\" \\n\\n\\n                Context: \\n {context}?\\n\\n                Question: \\n {question} \\n\\n                Answer:')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a single string of relevant documents given by Faiss.\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.llms import Cohere\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "load_dotenv()\n",
    "# RAG Chain\n",
    "\n",
    "def generate_answer(question):\n",
    "    cohere_llm = Cohere(model=\"command\", temperature=0.1, cohere_api_key = os.getenv('COHERE_API_KEY'))\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | cohere_llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    return rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The name of the college where the speaker obtained their B.Tech degree in Computer Science Engineering is Rayat Bahara University, Punjab. \n"
     ]
    }
   ],
   "source": [
    "ans = generate_answer(\"what is the name of College?\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The name of the person is: Vaibhav Sharma. \n",
      "\n",
      "I hope this helps, let me know if you have any other questions. \n"
     ]
    }
   ],
   "source": [
    "ans = generate_answer(\"what is the name of the person?\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the provided context, the individual has experience in several skills across different domains. However, a comprehensive list of the individual's skills is not explicitly mentioned in the information provided. \n",
      "\n",
      "Here's an extracted list of skills based on the context: \n",
      "\n",
      "- Machine Learning and Deep Learning Fundamentals\n",
      "- Full Stack Development\n",
      "- Data Analysis and Machine Learning\n",
      "- Data Management and Visualization\n",
      "- Programming and Tools (Python, Git)\n",
      "- Soft Skills (Problem Solving, Communication)\n",
      "- Data Cleaning and Data Preprocessing\n",
      "- Pandas\n",
      "- Numpy\n",
      "- Statistics\n",
      "- Linear Regression\n",
      "- k-means Clustering\n",
      "- Random Forest\n",
      "- Scikit-Learn\n",
      "- Feature Engineering\n",
      "- Model Evaluation\n",
      "- Predictive Modeling\n",
      "- Deep Learning Techniques\n",
      "- YOLOv3\n",
      "- Matplotlib\n",
      "- MySQL\n",
      "- MongoDB\n",
      "- DBMS\n",
      "- Jupyter Notebook\n",
      "- OpenCV\n",
      "- Object Detection in Real-Time Video Stream\n",
      "- Real-Time Object Detection Application\n",
      "- Frame Processing and Visualization\n",
      "- System Performance Optimization\n",
      "\n",
      "However, it's important to note that the provided context may be incomplete or selectively presented, and the actual scope of the individual's skills and experience may extend further. \n",
      "\n",
      "If you\n"
     ]
    }
   ],
   "source": [
    "ans = generate_answer(\"what are all the skills he have?\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
